# Vision AI Support - Resim Analizi

## ğŸ“· Durum: BETA (KÄ±smi Implementasyon)

Vision AI desteÄŸi eklendi! KullanÄ±cÄ±lar artÄ±k chat'e resim yÃ¼kleyebilir ve AI'ya gÃ¶sterebilir.

## âœ… Tamamlanan Ã–zellikler

### Frontend (100% TamamlandÄ±)
- âœ… Resim yÃ¼kleme butonu (ğŸ“· icon)
- âœ… Multi-image support (birden fazla resim)
- âœ… Base64 encoding
- âœ… Resim preview ve silme
- âœ… Format: `[IMAGES:n]\n[IMAGE_0]:base64...\n\nMessage`

### Backend (50% TamamlandÄ±)
- âœ… `chat_with_gguf_vision` Rust komutu eklendi
- âœ… Base64 image decoding
- âœ… Image validation
- âš ï¸ **mmproj yÃ¼kleme sistemi YOK** (kritik eksik)
- âš ï¸ **Vision embedding YOK** (kritik eksik)
- ğŸ”„ Åu an text-only fallback kullanÄ±yor

## ğŸ”§ Teknik Detaylar

### Rust Backend (`src-tauri/src/gguf.rs`)
```rust
#[tauri::command]
pub async fn chat_with_gguf_vision(
    state: State<'_, Arc<Mutex<GgufState>>>,
    prompt: String,
    images: Vec<String>, // Base64 encoded
    max_tokens: u32,
    temperature: f32,
) -> Result<String, String>
```

**Åu anki davranÄ±ÅŸ:**
- Resimleri base64'ten decode ediyor âœ…
- Resim sayÄ±sÄ±nÄ± loglara yazÄ±yor âœ…
- Text-only chat'e fallback yapÄ±yor âš ï¸
- KullanÄ±cÄ±ya "X resim gÃ¶nderildi ama vision iÅŸleme henÃ¼z yok" notu ekliyor

### Frontend (`src/services/aiProvider.ts`)
```typescript
function parseImagesFromMessage(message: string): { 
  cleanMessage: string; 
  images: string[] 
}
```

**Mesaj formatÄ±:**
```
[IMAGES:2]
[IMAGE_0]:data:image/png;base64,iVBORw0KG...
[IMAGE_1]:data:image/jpeg;base64,/9j/4AAQ...

KullanÄ±cÄ±nÄ±n mesajÄ± buraya gelir
```

## ğŸ¯ Vision Model Gereksinimleri

### 1. Vision-Capable GGUF Model
- **LLaVA 1.6** (Ã–nerilen) â­
- Qwen2-VL (mmproj henÃ¼z yok)
- Bakllava
- MobileVLM

### 2. mmproj DosyasÄ± (Vision Projector)
- **Kritik:** Her model iÃ§in Ã¶zel mmproj gerekli
- LLaVA mmproj â‰  Qwen mmproj
- Boyut: ~600 MB - 1.5 GB
- Format: `.gguf` veya `.bin`

### 3. llama.cpp Vision Support
- llama.cpp'nin vision branch'i gerekli
- `llama-cpp-2` crate'inin vision feature'Ä±

## ï¿½ Ã–rnek Model Ä°ndirme

### LLaVA 1.6 (Ã–nerilen)
```bash
# Model (7B Q4_K_M)
https://huggingface.co/cjpais/llava-1.6-mistral-7b-gguf/resolve/main/llava-v1.6-mistral-7b.Q4_K_M.gguf

# mmproj (Vision Encoder)
https://huggingface.co/cjpais/llava-1.6-mistral-7b-gguf/resolve/main/mmproj-model-f16.gguf
```

## ğŸš§ Eksik Ã–zellikler (TODO)

### 1. mmproj YÃ¼kleme Sistemi
```rust
// TODO: GgufState'e mmproj ekle
pub struct GgufState {
    pub backend: Option<LlamaBackend>,
    pub model: Option<LlamaModel>,
    pub mmproj: Option<MmProj>, // ğŸ†• Eklenecek
    pub model_path: Option<String>,
    pub mmproj_path: Option<String>, // ğŸ†• Eklenecek
    // ...
}
```

### 2. Vision Embedding
```rust
// TODO: Resimleri mmproj ile embed et
let image_embeddings = mmproj.encode_images(&decoded_images)?;
```

### 3. Multimodal Prompt
```rust
// TODO: Text + image embeddings'i birleÅŸtir
let multimodal_prompt = combine_text_and_images(prompt, image_embeddings)?;
```

## ğŸ® KullanÄ±m (Åu Anki Durum)

1. Chat panelinde ğŸ“· butonuna tÄ±kla
2. Resim seÃ§ (PNG, JPG, WebP)
3. Preview'da gÃ¶rÃ¼ntÃ¼le
4. Mesaj yaz ve gÃ¶nder
5. âš ï¸ AI resmi gÃ¶remez ama "X resim gÃ¶nderildi" notunu alÄ±r

## ğŸ”® Gelecek Planlar

### Faz 1: mmproj DesteÄŸi (P1)
- [ ] mmproj dosyasÄ± seÃ§me UI
- [ ] mmproj yÃ¼kleme fonksiyonu
- [ ] Model + mmproj eÅŸleÅŸtirme kontrolÃ¼

### Faz 2: Vision Inference (P1)
- [ ] Image embedding generation
- [ ] Multimodal prompt construction
- [ ] Vision model inference

### Faz 3: GeliÅŸmiÅŸ Ã–zellikler (P2)
- [ ] Resim crop/resize
- [ ] Multiple image support (ÅŸu an UI'da var, backend'de yok)
- [ ] Vision model karÅŸÄ±laÅŸtÄ±rma
- [ ] OCR optimizasyonu

## ğŸ“ Notlar

- **12 GB VRAM:** LLaVA 1.6 7B Q4_K_M rahatÃ§a Ã§alÄ±ÅŸÄ±r
- **mmproj boyutu:** Model boyutuna ek ~1 GB VRAM
- **Context length:** Vision modeller genelde 4K-8K context kullanÄ±r
- **Performance:** Vision inference text-only'den ~2-3x daha yavaÅŸ

## ğŸ”— Kaynaklar

- [LLaVA Models](https://huggingface.co/cjpais/llava-1.6-mistral-7b-gguf)
- [llama.cpp Vision](https://github.com/ggerganov/llama.cpp/tree/master/examples/llava)
- [Qwen2-VL](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct-GGUF)

---

**Son GÃ¼ncelleme:** Vision AI backend komutu eklendi, mmproj implementasyonu bekleniyor.
