# TASK 26: Model Registry + Auto Backend Selection

**Tarih:** 8 Åubat 2026  
**Durum:** âœ… TAMAMLANDI  
**SÃ¼re:** ~2 saat

## ğŸ“‹ Ã–zet

Model Registry sistemi - Otomatik VRAM tespiti, backend Ã¶nerisi, quantization algÄ±lama ve akÄ±llÄ± GPU layer hesaplama.

## ğŸ¯ Hedef

- Auto VRAM Detection - GPU bellek tespiti
- Backend Recommendation - CUDA/Vulkan Ã¶nerisi
- Quantization Detection - Otomatik quant algÄ±lama
- Model Metadata Reader - GGUF metadata okuma
- Smart GPU Layer Calculation - Otomatik GPU layer Ã¶nerisi

## ğŸ†• Yeni Servis: modelRegistry.ts

### Ã–zellikler

**1. Model Metadata Okuma**
```typescript
interface ModelMetadata {
  name: string;
  architecture: string;
  parameters: number; // Billion (7.0 for 7B)
  quantization: string;
  fileSizeGB: number;
  contextLength: number;
  estimatedVRAM: {
    min: number;
    recommended: number;
    withContext: number;
  };
  recommendedBackend: 'cuda' | 'vulkan' | 'cpu';
  recommendedGPULayers: number;
}
```

**2. GPU Info Detection**
```typescript
interface GPUInfo {
  available: boolean;
  vendor: 'nvidia' | 'amd' | 'intel' | 'apple' | 'unknown';
  name: string;
  totalVRAM_GB: number;
  freeVRAM_GB: number;
  cudaAvailable: boolean;
  vulkanAvailable: boolean;
  recommendedBackend: 'cuda' | 'vulkan' | 'cpu';
}
```

**3. Backend Recommendation**
```typescript
interface BackendRecommendation {
  backend: 'cuda' | 'vulkan' | 'cpu';
  reason: string;
  gpuLayers: number;
  expectedPerformance: 'excellent' | 'good' | 'moderate' | 'slow';
  warnings: string[];
}
```

## ğŸ”§ YapÄ±lan DeÄŸiÅŸiklikler

### 1. Model Registry Service (`src/services/modelRegistry.ts`)

**Fonksiyonlar:**

```typescript
// Model metadata okuma
async function readModelMetadata(modelPath: string): Promise<ModelMetadata>

// GPU bilgilerini al
async function getGPUInfo(): Promise<GPUInfo>

// Backend Ã¶nerisi al
async function getBackendRecommendation(modelPath: string): Promise<BackendRecommendation>

// Optimal GPU layers hesapla
function calculateOptimalGPULayers(
  modelSizeGB: number,
  availableVRAM_GB: number,
  contextLength: number
): number
```

**VRAM Hesaplama:**
```typescript
// Base VRAM = file size
const baseVRAM = fileSizeGB;

// Quantization multiplier
const quantMultiplier = getQuantizationMultiplier(quantization);
// Q2_K: 0.35, Q4_K_M: 0.55, Q6_K: 0.8, F16: 1.0

// Context overhead (KV cache)
const contextOverhead = (contextLength / 1000) * parameters * 0.0001;

// Minimum VRAM (just model)
const min = Math.ceil(baseVRAM * quantMultiplier);

// Recommended VRAM (model + small context)
const recommended = Math.ceil(baseVRAM * quantMultiplier * 1.2 + contextOverhead * 0.5);

// With full context
const withContext = Math.ceil(baseVRAM * quantMultiplier * 1.2 + contextOverhead);
```

**GPU Vendor Detection:**
```typescript
function detectGPUVendor(message: string): 'nvidia' | 'amd' | 'intel' | 'apple' | 'unknown' {
  const lowerMsg = message.toLowerCase();
  
  if (lowerMsg.includes('nvidia') || lowerMsg.includes('cuda')) return 'nvidia';
  if (lowerMsg.includes('amd') || lowerMsg.includes('radeon')) return 'amd';
  if (lowerMsg.includes('intel')) return 'intel';
  if (lowerMsg.includes('apple') || lowerMsg.includes('metal')) return 'apple';
  
  return 'unknown';
}
```

**Backend Selection Logic:**
```typescript
function determineRecommendedBackend(
  cudaAvailable: boolean,
  vulkanAvailable: boolean,
  vendor: string
): 'cuda' | 'vulkan' | 'cpu' {
  // NVIDIA: Prefer CUDA
  if (vendor === 'nvidia' && cudaAvailable) return 'cuda';
  
  // AMD/Intel: Prefer Vulkan
  if ((vendor === 'amd' || vendor === 'intel') && vulkanAvailable) return 'vulkan';
  
  // Fallback: Vulkan > CUDA > CPU
  if (vulkanAvailable) return 'vulkan';
  if (cudaAvailable) return 'cuda';
  return 'cpu';
}
```

**GPU Layer Calculation:**
```typescript
function calculateOptimalGPULayers(
  modelSizeGB: number,
  availableVRAM_GB: number,
  contextLength: number = 4096
): number {
  // Leave 10% buffer
  const usableVRAM = availableVRAM_GB * 0.9;
  
  // Context overhead
  const contextOverhead = (contextLength / 4096) * 0.5; // ~0.5GB per 4K context
  
  // Available for model
  const availableForModel = usableVRAM - contextOverhead;
  
  // Layer ratio
  const layerRatio = availableForModel / modelSizeGB;
  
  // Calculate layers (assume 33 layers for 7B models)
  const totalLayers = 33;
  const gpuLayers = Math.floor(layerRatio * totalLayers);
  
  // Clamp between 0 and totalLayers
  return Math.max(0, Math.min(gpuLayers, totalLayers));
}
```

### 2. GGUF Model Browser Integration

**GPU Info Display:**
```tsx
{gpuInfo && gpuInfo.available && (
  <div className="p-2 bg-gradient-to-br from-cyan-900/30 to-teal-900/30 border border-cyan-500/30 rounded-lg">
    <h4 className="text-xs font-semibold text-cyan-400">ğŸ® GPU Bilgileri</h4>
    <div className="space-y-1 text-xs">
      <div>Model: {gpuInfo.name}</div>
      <div>VRAM: {gpuInfo.totalVRAM_GB.toFixed(1)} GB</div>
      <div>BoÅŸ VRAM: {gpuInfo.freeVRAM_GB.toFixed(1)} GB</div>
      <div>Ã–nerilen Backend: {gpuInfo.recommendedBackend.toUpperCase()}</div>
    </div>
  </div>
)}
```

**Backend Recommendation Display:**
```tsx
{backendRecommendation && (
  <div className="p-2 rounded-lg border">
    <h4>ğŸ¯ Bu Model Ä°Ã§in Ã–neri</h4>
    <div>Backend: {backendRecommendation.backend.toUpperCase()}</div>
    <div>GPU Layers: {backendRecommendation.gpuLayers}/33</div>
    <div>Performans: {backendRecommendation.expectedPerformance}</div>
    <p>{backendRecommendation.reason}</p>
    
    {backendRecommendation.warnings.map(warning => (
      <p className="text-yellow-400">{warning}</p>
    ))}
    
    <button onClick={() => setGpuLayers(backendRecommendation.gpuLayers)}>
      âœ¨ Ã–nerilen AyarÄ± Uygula
    </button>
  </div>
)}
```

**Auto GPU Layer Setting:**
```typescript
// Model seÃ§ildiÄŸinde otomatik backend Ã¶nerisi
const handleModelSelect = async (model: GGUFModel) => {
  if (!model.isDownloaded) return;
  
  setSelectedModelForConfig(model);
  
  // Backend Ã¶nerisi al
  if (model.localPath) {
    const { getBackendRecommendation } = await import('../services/modelRegistry');
    const recommendation = await getBackendRecommendation(model.localPath);
    setBackendRecommendation(recommendation);
    
    // Auto-set GPU layers
    setGpuLayers(recommendation.gpuLayers);
    
    // Show toast
    if (recommendation.warnings.length > 0) {
      showToast(recommendation.warnings[0], 'warning');
    } else {
      showToast(
        `âœ… ${recommendation.backend.toUpperCase()} Ã¶neriliyor - ${recommendation.expectedPerformance} performans`,
        'success'
      );
    }
  }
};
```

**GPU Detection on Load:**
```typescript
useEffect(() => {
  // GPU Info Detection
  const detectGPU = async () => {
    const { getGPUInfo } = await import('../services/modelRegistry');
    const info = await getGPUInfo();
    setGpuInfo(info);
    
    // Auto-set GPU layers based on VRAM
    if (info.available && info.totalVRAM_GB > 0) {
      const { calculateOptimalGPULayers } = await import('../services/modelRegistry');
      const optimalLayers = calculateOptimalGPULayers(4, info.freeVRAM_GB, contextLength);
      setGpuLayers(optimalLayers);
      console.log(`ğŸ¯ Optimal GPU layers: ${optimalLayers}/33`);
    }
  };
  
  detectGPU();
}, []);
```

**Enhanced Metadata Reader:**
```typescript
const readModelMetadata = async (modelPath: string) => {
  showToast('Metadata okunuyor...', 'info');
  
  // Model Registry kullan
  const { readModelMetadata: readMeta } = await import('../services/modelRegistry');
  const metadata = await readMeta(modelPath);
  
  setModelMetadata(metadata);
  
  // Show detailed info
  const info = `
ğŸ“Š Model Bilgileri:
â€¢ Parametre: ${metadata.parameters}B
â€¢ Quantization: ${metadata.quantization}
â€¢ Context: ${(metadata.contextLength / 1000).toFixed(0)}K tokens
â€¢ Boyut: ${metadata.fileSizeGB.toFixed(1)} GB

ğŸ® VRAM Gereksinimleri:
â€¢ Minimum: ${metadata.estimatedVRAM.min} GB
â€¢ Ã–nerilen: ${metadata.estimatedVRAM.recommended} GB
â€¢ Full Context: ${metadata.estimatedVRAM.withContext} GB

âš¡ Backend Ã–nerisi:
â€¢ ${metadata.recommendedBackend.toUpperCase()}
â€¢ GPU Layers: ${metadata.recommendedGPULayers}/33
  `.trim();
  
  console.log(info);
  showToast('Metadata baÅŸarÄ±yla okundu!', 'success');
};
```

## ğŸ“Š KullanÄ±m SenaryolarÄ±

### Senaryo 1: Model SeÃ§imi - Otomatik Ã–neri

```
User: Qwen2.5-Coder-7B-Q4_K_M.gguf seÃ§er

System:
1. GPU tespit edilir (NVIDIA RTX 3060, 12GB VRAM)
2. Model metadata okunur:
   - 7B parameters
   - Q4_K_M quantization
   - 4.2 GB file size
3. VRAM hesaplanÄ±r:
   - Min: 3 GB
   - Recommended: 4 GB
   - With 32K context: 5 GB
4. Backend Ã¶nerisi:
   - CUDA (NVIDIA GPU)
   - 33/33 GPU layers (full offload)
   - Expected: Excellent performance
5. GPU layers otomatik ayarlanÄ±r: 33

Toast: "âœ… CUDA Ã¶neriliyor - excellent performans"
```

### Senaryo 2: Yetersiz VRAM - KÄ±smi Offload

```
User: Llama-3.1-70B-Q4_K_M.gguf seÃ§er

System:
1. GPU: NVIDIA RTX 3060, 12GB VRAM
2. Model: 40 GB file size
3. VRAM hesaplama:
   - Min: 22 GB
   - Recommended: 26 GB
   - Available: 11 GB (free)
4. Backend Ã¶nerisi:
   - CUDA
   - 14/33 GPU layers (partial offload)
   - Expected: Moderate performance
   - Warning: "âš ï¸ Yetersiz VRAM - 26GB gerekli, 11GB mevcut"
5. GPU layers otomatik ayarlanÄ±r: 14

Toast: "âš ï¸ Yetersiz VRAM - 26GB gerekli, 11GB mevcut"
```

### Senaryo 3: AMD GPU - Vulkan Ã–nerisi

```
User: Mistral-7B-Q5_K_M.gguf seÃ§er

System:
1. GPU: AMD Radeon RX 6800, 16GB VRAM
2. Model: 5.5 GB file size
3. Backend detection:
   - CUDA: Not available
   - Vulkan: Available
4. Backend Ã¶nerisi:
   - Vulkan (AMD GPU)
   - 33/33 GPU layers
   - Expected: Good performance
5. GPU layers otomatik ayarlanÄ±r: 33

Toast: "âœ… Vulkan Ã¶neriliyor - good performans"
```

### Senaryo 4: CPU Fallback

```
User: Phi-3-Mini-Q4_K_M.gguf seÃ§er

System:
1. GPU: Not detected
2. Model: 2.3 GB file size
3. Backend Ã¶nerisi:
   - CPU
   - 0/33 GPU layers
   - Expected: Slow performance
   - Warning: "âš ï¸ GPU bulunamadÄ± - CPU kullanÄ±lacak (yavaÅŸ)"
5. GPU layers: 0

Toast: "âš ï¸ GPU bulunamadÄ± - CPU kullanÄ±lacak (yavaÅŸ)"
```

## ğŸ¨ UI GeliÅŸtirmeleri

### 1. GPU Info Panel

**GÃ¶rÃ¼nÃ¼m:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ® GPU Bilgileri      [NVIDIA]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model: NVIDIA GeForce RTX 3060  â”‚
â”‚ VRAM: 12.0 GB                   â”‚
â”‚ BoÅŸ VRAM: 10.5 GB               â”‚
â”‚ Ã–nerilen Backend: CUDA          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Renk KodlarÄ±:**
- NVIDIA: YeÅŸil
- AMD: KÄ±rmÄ±zÄ±
- Intel: Mavi
- Unknown: Gri

### 2. Backend Recommendation Panel

**MÃ¼kemmel Performans (Excellent):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ Bu Model Ä°Ã§in Ã–neri [âš¡ MÃ¼kemmel] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Backend: CUDA                   â”‚
â”‚ GPU Layers: 33/33               â”‚
â”‚                                 â”‚
â”‚ NVIDIA GPU tespit edildi -      â”‚
â”‚ CUDA en iyi performansÄ± verir   â”‚
â”‚                                 â”‚
â”‚ [âœ¨ Ã–nerilen AyarÄ± Uygula]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Yetersiz VRAM (Moderate):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ Bu Model Ä°Ã§in Ã–neri [âš ï¸ Orta] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Backend: CUDA                   â”‚
â”‚ GPU Layers: 14/33               â”‚
â”‚                                 â”‚
â”‚ âš ï¸ Yetersiz VRAM - 26GB gerekli,â”‚
â”‚    11GB mevcut                  â”‚
â”‚ âš ï¸ KÄ±smi GPU offload - 14/33    â”‚
â”‚    layer GPU'da                 â”‚
â”‚                                 â”‚
â”‚ [âœ¨ Ã–nerilen AyarÄ± Uygula]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Metadata Display

**GeliÅŸtirilmiÅŸ Metadata:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Model Metadata          [âœ•]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Parametre: 7B                   â”‚
â”‚ Quantization: Q4_K_M            â”‚
â”‚ Context: 32K tokens             â”‚
â”‚ Boyut: 4.2 GB                   â”‚
â”‚                                 â”‚
â”‚ ğŸ® VRAM Gereksinimleri:         â”‚
â”‚ â€¢ Minimum: 3 GB                 â”‚
â”‚ â€¢ Ã–nerilen: 4 GB                â”‚
â”‚ â€¢ Full Context: 5 GB            â”‚
â”‚                                 â”‚
â”‚ âš¡ Backend Ã–nerisi:              â”‚
â”‚ â€¢ CUDA                          â”‚
â”‚ â€¢ GPU Layers: 33/33             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Quantization Multipliers

```typescript
const QUANT_MULTIPLIERS = {
  'Q2_K': 0.35,    // En kÃ¼Ã§Ã¼k, en hÄ±zlÄ±
  'Q3_K_S': 0.4,
  'Q3_K_M': 0.45,
  'Q3_K_L': 0.5,
  'Q4_0': 0.5,
  'Q4_1': 0.55,
  'Q4_K_S': 0.5,
  'Q4_K_M': 0.55,  // Ã–nerilen - dengeli
  'Q5_0': 0.65,
  'Q5_1': 0.7,
  'Q5_K_S': 0.65,
  'Q5_K_M': 0.7,   // YÃ¼ksek kalite
  'Q6_K': 0.8,     // Ã‡ok yÃ¼ksek kalite
  'Q8_0': 0.95,    // En yÃ¼ksek kalite
  'F16': 1.0,      // Full precision
  'F32': 2.0       // Double precision
};
```

## ğŸ¯ Backend Selection Priority

**NVIDIA GPU:**
1. CUDA (if available) âœ… Best
2. Vulkan (fallback)
3. CPU (last resort)

**AMD GPU:**
1. Vulkan âœ… Best
2. CPU (fallback)

**Intel GPU:**
1. Vulkan âœ… Best
2. CPU (fallback)

**Apple Silicon:**
1. Metal âœ… Best
2. CPU (fallback)

**No GPU:**
1. CPU only

## ğŸ”— Ä°lgili Dosyalar

**Yeni:**
- âœ… `src/services/modelRegistry.ts` - Model Registry service

**GÃ¼ncellenen:**
- âœ… `src/components/GGUFModelBrowser.tsx` - GPU info & backend recommendation UI

## ğŸ“ Ã–ÄŸrenilen Dersler

1. **VRAM Hesaplama:** Quantization multiplier + context overhead = accurate VRAM estimate
2. **GPU Vendor Detection:** Backend message parsing works well
3. **Auto Layer Calculation:** Simple ratio-based calculation is effective
4. **User Experience:** Auto-recommendations save time and prevent errors

## ğŸš€ Sonraki AdÄ±mlar

**Tamamlanan (Blueprint):**
- âœ… Tool Abstraction Layer
- âœ… AI Agent Loop
- âœ… Terminal Intelligence
- âœ… Multi-Agent System
- âœ… Model Registry + Auto Backend â¬…ï¸ YENÄ°!

**Kalan (Blueprint):**
- ğŸ”œ Semantic Brain (AST + Dependency Graph) - 4-5 saat
- ğŸ”œ Infinite Context Illusion - 6-8 saat
- ğŸ”œ Ghost Developer Mode - 2-3 saat

---

**SÃ¼re:** 2 saat (tahmin: 2-3 saat) âœ…

**SonuÃ§:** Model Registry sistemi Ã§alÄ±ÅŸÄ±yor! Otomatik VRAM tespiti, backend Ã¶nerisi ve akÄ±llÄ± GPU layer hesaplama aktif.

