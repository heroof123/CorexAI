================================================================================
                    COREX IDE - MİMARİ ÖZET
================================================================================

## GENEL YAPI

3 Katmanlı Mimari:
  Frontend (React 19 + TypeScript) 
    ↕
  Services (Business Logic)
    ↕
  Backend (Rust + Tauri 2)

## TEKNOLOJİLER

Frontend:
- React 19, TypeScript 5.8, Vite 7
- Monaco Editor (kod editörü)
- Tailwind CSS (styling)
- Xenova Transformers (embeddings)

Backend:
- Tauri 2 (desktop framework)
- Rust 2021
- llama-cpp-2 (local LLM)
- tokio (async runtime)

Database:
- IndexedDB (file index, embeddings)
- LocalStorage (settings, cache)

## KLASÖR YAPISI

src/
├── components/          # UI bileşenleri (60+ dosya)
├── services/           # Business logic
│   ├── aiProvider.ts   # AI model yönetimi
│   ├── contextProvider.ts  # Context oluşturma
│   ├── embedding.ts    # Semantic search
│   ├── cache.ts        # LRU cache
│   └── auth.ts         # OAuth
├── contexts/           # React contexts (Theme, Language)
└── types/              # TypeScript types

src-tauri/src/
├── main.rs             # Entry point
├── commands.rs         # File operations
├── gguf.rs             # Local LLM support
├── oauth.rs            # OAuth callback server
└── oauth_backend.rs    # Token exchange (güvenli)

## TEMEL AKIŞLAR

1. AI Chat:
   User Input → Context Builder → AI Provider → LLM → Response

2. File Indexing:
   Scan Files → Detect Changes → Create Embeddings → Store IndexedDB

3. OAuth:
   User Click → Open Browser → Callback → Token Exchange (Backend) → Store

## AI ENTEGRASYONU

Desteklenen Modeller:
- LM Studio (HTTP API)
- Ollama (HTTP API)
- GGUF Direct (llama.cpp - CPU/CUDA)

Embedding Model:
- BGE-small-en-v1.5 (384 dim)
- Browser-based (Transformers.js)

RAG (Retrieval-Augmented Generation):
Query → Embedding → Semantic Search → Context → LLM → Response

## GÜVENLİK

✅ OAuth token exchange backend'de
✅ Client secrets environment variables'da
✅ Error boundary (crash handling)
✅ Environment validation
✅ Centralized logging

## PERFORMANS

Cache Strategy:
- Memory (LRU): Embeddings (1000), AI responses (100)
- IndexedDB: Persistent storage
- Hit rate: ~80%

Incremental Indexing:
- Sadece değişen dosyalar indexlenir
- Batch processing (10 dosya/batch)
- 1000 dosya: İlk 45s, sonraki 2s

## BUILD

Development:
  npm run tauri:dev

Production:
  npm run tauri:build
  → Windows: .msi, .exe
  → macOS: .dmg, .app
  → Linux: .deb, .AppImage

## METRIKLER

Bundle Size: 5.8 MB (1.4 MB gzipped)
Memory: ~4.5 GB (7B model ile)
Startup: 2.5s
File Open: 150ms
AI Response: 3-8s (model'e göre)

================================================================================
