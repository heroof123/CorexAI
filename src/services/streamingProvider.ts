// Streaming AI Response Provider
import { invoke } from "@tauri-apps/api/core";

export interface StreamingConfig {
  onToken?: (token: string) => void;
  onComplete?: (fullText: string) => void;
  onError?: (error: string) => void;
}

// Simulated streaming (chunk-based)
// GerÃ§ek streaming iÃ§in Rust backend'de event emit gerekli
export async function chatWithStreaming(
  prompt: string,
  maxTokens: number,
  temperature: number,
  config: StreamingConfig
): Promise<string> {
  try {
    // Åžimdilik: TÃ¼m cevabÄ± al, sonra chunk'lara bÃ¶l
    const fullResponse = await invoke<string>('chat_with_gguf_model', {
      prompt,
      maxTokens,
      temperature
    });

    // Simulate streaming by splitting into words
    if (config.onToken) {
      const words = fullResponse.split(' ');
      let accumulated = '';
      
      for (let i = 0; i < words.length; i++) {
        const word = words[i];
        accumulated += (i > 0 ? ' ' : '') + word;
        
        // Emit token
        config.onToken(accumulated);
        
        // Small delay to simulate streaming
        await new Promise(resolve => setTimeout(resolve, 30));
      }
    }

    if (config.onComplete) {
      config.onComplete(fullResponse);
    }

    return fullResponse;
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    if (config.onError) {
      config.onError(errorMsg);
    }
    throw error;
  }
}

// Chunk-based streaming (better simulation)
export async function chatWithChunkedStreaming(
  prompt: string,
  maxTokens: number,
  temperature: number,
  config: StreamingConfig
): Promise<string> {
  try {
    const fullResponse = await invoke<string>('chat_with_gguf_model', {
      prompt,
      maxTokens,
      temperature
    });

    // Split into chunks for smoother streaming (not character by character)
    if (config.onToken) {
      let accumulated = '';
      const chars = fullResponse.split('');
      
      // ðŸ”¥ FIXED: Chunk size artÄ±rÄ±ldÄ± (5 karakter), delay azaltÄ±ldÄ± (2ms)
      // Bu sayede daha az gÃ¼ncelleme, daha az jitter
      const chunkSize = 5; // 5 karakter birden
      
      for (let i = 0; i < chars.length; i += chunkSize) {
        const chunk = chars.slice(i, i + chunkSize).join('');
        accumulated += chunk;
        config.onToken(accumulated);
        
        // Daha az delay - daha smooth
        await new Promise(resolve => setTimeout(resolve, 2));
      }
    }

    if (config.onComplete) {
      config.onComplete(fullResponse);
    }

    return fullResponse;
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    if (config.onError) {
      config.onError(errorMsg);
    }
    throw error;
  }
}
